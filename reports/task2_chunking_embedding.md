**Task 2 Report Paragraph — Text Chunking, Embedding & Indexing**

In Task 2, I transformed the cleaned consumer complaint narratives into semantic-search-ready chunks and vector embeddings. To handle the variable length of complaints, I used LangChain’s `RecursiveCharacterTextSplitter` with a chunk size of **200 characters** and an overlap of **50**, which helped preserve context across chunk boundaries while keeping the segments small enough for efficient embedding. Each narrative was split into multiple chunks, resulting in over **20,000 text chunks** for around **82,000 filtered complaints**, ensuring that even long narratives are searchable in smaller, meaningful segments.

For embedding, I selected the **`all-MiniLM-L6-v2`** model from Sentence Transformers because it is a lightweight, high-quality model optimized for short English texts, providing a good balance of speed and semantic accuracy for the complaint narratives. Using this model, I generated dense vector representations for all chunks and stored them in a **FAISS vector index**. To support traceability, each vector is linked with metadata — including the original **complaint ID** and **product category** — stored separately in a CSV file. This setup ensures that the semantic search can return relevant complaint snippets along with their source details, forming the backbone of the chatbot’s retrieval capability.
